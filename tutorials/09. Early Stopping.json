{"paragraphs":[{"text":"%md\n\n### Background\n\nWhen training neural networks, it is important to avoid overfitting the training data. Overfitting occurs when the neural network learns the noise in the training data and thus does not generalize well to data it has not been trained on. One hyperparameter that affects whether the neural network will overfit or not is the number of epochs or complete passes through the training split. If we use too many epochs, then the neural network is likely to overfit. On the other hand, if we use too few epochs, the neural network might not have the chance to learn fully from the training data.\n\nEarly stopping is one mechanism used to manually set the number of epochs to prevent underfitting and overfitting. The idea behind early stopping is intuitive. First the data is split into training and testing sets. At the end of each epoch, the neural network is evaluated on the test set. If the neural network outperforms the previous best model, then we save the neural network. The best overall model is then taken to be the final model. \n\nIn this tutorial we will show how to use early stopping with deeplearning4j (DL4J). We will apply the method on a feed forward neural network using the MNIST dataset, which is a dataset consisting of handwritten digits.\n\n","dateUpdated":"2017-11-10T00:03:12+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Background</h3>\n<p>When training neural networks, it is important to avoid overfitting the training data. Overfitting occurs when the neural network learns the noise in the training data and thus does not generalize well to data it has not been trained on. One hyperparameter that affects whether the neural network will overfit or not is the number of epochs or complete passes through the training split. If we use too many epochs, then the neural network is likely to overfit. On the other hand, if we use too few epochs, the neural network might not have the chance to learn fully from the training data.</p>\n<p>Early stopping is one mechanism used to manually set the number of epochs to prevent underfitting and overfitting. The idea behind early stopping is intuitive. First the data is split into training and testing sets. At the end of each epoch, the neural network is evaluated on the test set. If the neural network outperforms the previous best model, then we save the neural network. The best overall model is then taken to be the final model. </p>\n<p>In this tutorial we will show how to use early stopping with deeplearning4j (DL4J). We will apply the method on a feed forward neural network using the MNIST dataset, which is a dataset consisting of handwritten digits.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510271453900_-572128881","id":"20171108-224832_1458853760","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:368","user":"anonymous","dateFinished":"2017-11-10T00:03:12+0000","dateStarted":"2017-11-10T00:03:12+0000"},{"text":"%md\n### Imports","dateUpdated":"2017-11-09T23:51:09+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Imports</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1510271453927_-2105479153","id":"20171108-224958_664143393","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:369","user":"anonymous","dateFinished":"2017-11-09T23:51:09+0000","dateStarted":"2017-11-09T23:51:09+0000"},{"text":"import org.apache.commons.io.FilenameUtils;\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.dataset.api.iterator.DataSetIterator\nimport org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\nimport org.deeplearning4j.earlystopping.EarlyStoppingConfiguration;\nimport org.deeplearning4j.earlystopping.EarlyStoppingModelSaver;\nimport org.deeplearning4j.earlystopping.EarlyStoppingResult;\nimport org.deeplearning4j.earlystopping.saver.LocalFileModelSaver;\nimport org.deeplearning4j.earlystopping.scorecalc.DataSetLossCalculator;\nimport org.deeplearning4j.earlystopping.termination.MaxEpochsTerminationCondition;\nimport org.deeplearning4j.earlystopping.termination.MaxTimeIterationTerminationCondition;\nimport org.deeplearning4j.earlystopping.trainer.EarlyStoppingTrainer;\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.conf.MultiLayerConfiguration\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration\nimport org.deeplearning4j.nn.conf.Updater\nimport org.deeplearning4j.nn.conf.layers.DenseLayer\nimport org.deeplearning4j.nn.conf.layers.OutputLayer\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.optimize.listeners.ScoreIterationListener\nimport org.nd4j.linalg.api.ndarray.INDArray\nimport org.nd4j.linalg.dataset.DataSet\nimport org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\n\nimport java.io.File;\nimport java.util.concurrent.TimeUnit;\n","dateUpdated":"2017-11-09T23:51:11+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.commons.io.FilenameUtils\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.dataset.api.iterator.DataSetIterator\nimport org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\nimport org.deeplearning4j.earlystopping.EarlyStoppingConfiguration\nimport org.deeplearning4j.earlystopping.EarlyStoppingModelSaver\nimport org.deeplearning4j.earlystopping.EarlyStoppingResult\nimport org.deeplearning4j.earlystopping.saver.LocalFileModelSaver\nimport org.deeplearning4j.earlystopping.scorecalc.DataSetLossCalculator\nimport org.deeplearning4j.earlystopping.termination.MaxEpochsTerminationCondition\nimport org.deeplearning4j.earlystopping.termination.MaxTimeIterationTerminationCondition\nimport org.deeplearning4j.earlystopping.trainer.EarlyStoppingTrainer\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.conf.MultiLayerConfiguration\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration\nimport org.deeplearning4j.nn.conf.Updater\nimport org.deeplearning4j.nn.conf.layers.DenseLayer\nimport org.deeplearning4j.nn.conf.layers.OutputLayer\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.optimize.listeners.ScoreIterationListener\nimport org.nd4j.linalg.api.ndarray.INDArray\nimport org.nd4j.linalg.dataset.DataSet\nimport org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport java.io.File\nimport java.util.concurrent.TimeUnit\n"}]},"apps":[],"jobName":"paragraph_1510271453928_1989974919","id":"20171108-225047_1837703499","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:370","user":"anonymous","dateFinished":"2017-11-09T23:52:08+0000","dateStarted":"2017-11-09T23:51:11+0000"},{"text":"%md\n\nNow that we have imported everything needed to run this tutorial, we can start by setting the parameters for the neural network and initializing the data. We will set the maximum number of epochs to run early stopping on to be 15.","dateUpdated":"2017-11-09T23:51:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now that we have imported everything needed to run this tutorial, we can start by setting the parameters for the neural network and initializing the data. We will set the maximum number of epochs to run early stopping on to be 15.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510271453931_784590024","id":"20171108-225748_224585712","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:371","user":"anonymous","dateFinished":"2017-11-09T23:52:08+0000","dateStarted":"2017-11-09T23:52:08+0000"},{"text":"val numRows = 28\nval numColumns = 28\nval outputNum = 10 \nval batchSize = 128\nval rngSeed = 123\n\nval mnistTrain: DataSetIterator = new MnistDataSetIterator(batchSize, true, rngSeed)\nval mnistTest: DataSetIterator = new MnistDataSetIterator(batchSize, false, rngSeed)\n\n","dateUpdated":"2017-11-09T23:52:55+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"numRows: Int = 28\nnumColumns: Int = 28\noutputNum: Int = 10\nbatchSize: Int = 128\nrngSeed: Int = 123\nmnistTrain: org.nd4j.linalg.dataset.api.iterator.DataSetIterator = org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator@3eaf8e8f\nmnistTest: org.nd4j.linalg.dataset.api.iterator.DataSetIterator = org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator@3332e6f7\n"}]},"apps":[],"jobName":"paragraph_1510271453932_-247758100","id":"20171108-225007_1943293802","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:372","user":"anonymous","dateFinished":"2017-11-09T23:53:02+0000","dateStarted":"2017-11-09T23:52:55+0000"},{"text":"%md\n\nNext we will set the neural network configuration using the MultiLayerNetwork class of DL4J and initialize the MultiLayerNetwork.","dateUpdated":"2017-11-09T23:52:57+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Next we will set the neural network configuration using the MultiLayerNetwork class of DL4J and initialize the MultiLayerNetwork.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510271453932_-956780114","id":"20171108-225900_40053262","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:373","user":"anonymous","dateFinished":"2017-11-09T23:53:02+0000","dateStarted":"2017-11-09T23:53:02+0000"},{"text":"val conf : MultiLayerConfiguration = new NeuralNetConfiguration.Builder()\n                .seed(rngSeed) //include a random seed for reproducibility\n                // use stochastic gradient descent as an optimization algorithm\n                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n                .iterations(1)\n                .learningRate(0.006) //specify the learning rate\n                .updater(Updater.NESTEROVS)\n                .regularization(true).l2(1e-4)\n                .list()\n                .layer(0, new DenseLayer.Builder() //create the first, input layer with xavier initialization\n                        .nIn(numRows * numColumns)\n                        .nOut(1000)\n                        .activation(Activation.RELU)\n                        .weightInit(WeightInit.XAVIER)\n                        .build())\n                .layer(1, new OutputLayer.Builder(LossFunction.NEGATIVELOGLIKELIHOOD) //create hidden layer\n                        .nIn(1000)\n                        .nOut(outputNum)\n                        .activation(Activation.SOFTMAX)\n                        .weightInit(WeightInit.XAVIER)\n                        .build())\n                .pretrain(false).backprop(true) //use backpropagation to adjust weights\n                .build()\n                \nval model : MultiLayerNetwork = new MultiLayerNetwork(conf)","dateUpdated":"2017-11-09T23:54:39+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"conf: org.deeplearning4j.nn.conf.MultiLayerConfiguration =\n{\n  \"backprop\" : true,\n  \"backpropType\" : \"Standard\",\n  \"cacheMode\" : \"NONE\",\n  \"confs\" : [ {\n    \"cacheMode\" : \"NONE\",\n    \"iterationCount\" : 0,\n    \"l1ByParam\" : { },\n    \"l2ByParam\" : { },\n    \"layer\" : {\n      \"dense\" : {\n        \"activationFn\" : {\n          \"ReLU\" : { }\n        },\n        \"adamMeanDecay\" : \"NaN\",\n        \"adamVarDecay\" : \"NaN\",\n        \"biasInit\" : 0.0,\n        \"biasLearningRate\" : 0.006,\n        \"dist\" : null,\n        \"dropOut\" : 0.0,\n        \"epsilon\" : \"NaN\",\n        \"gradientNormalization\" : \"None\",\n        \"gradientNormalizationThreshold\" : 1.0,\n        \"iupdater\" : {\n          \"@class\" : \"org.nd4j.linalg.learning.config.Nesterovs\",\n          \"learningRate\" : 0.006,\n          \"momentum\" : 0.9\n        }...model: org.deeplearning4j.nn.multilayer.MultiLayerNetwork = org.deeplearning4j.nn.multilayer.MultiLayerNetwork@7fda1b5e\n"}]},"apps":[],"jobName":"paragraph_1510271453932_-1435069149","id":"20171108-225941_694043039","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:374","user":"anonymous","dateFinished":"2017-11-09T23:53:39+0000","dateStarted":"2017-11-09T23:53:05+0000"},{"text":"%md\n\nIf we weren't using early stopping, we would proceed by training the neural network using for loops and the fit method of the MultiLayerNetwork. But since we are using early stopping we need to configure how early stopping will be applied. Looking at the next cell, we will use a maximum epoch number of 30 and a maximum training time of 20 minutes. The evaluation will be done on mnistTest after each epoch.\n\nOnce the EarlyStoppingConfiguration is specified, we only need to initialize an EarlyStoppingTrainer using the training data and the two previous configuraitons. The results are obtained just by calling the fit method of EarlyStoppingTrainer.","dateUpdated":"2017-11-09T23:53:07+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>If we weren&rsquo;t using early stopping, we would proceed by training the neural network using for loops and the fit method of the MultiLayerNetwork. But since we are using early stopping we need to configure how early stopping will be applied. Looking at the next cell, we will use a maximum epoch number of 30 and a maximum training time of 20 minutes. The evaluation will be done on mnistTest after each epoch.</p>\n<p>Once the EarlyStoppingConfiguration is specified, we only need to initialize an EarlyStoppingTrainer using the training data and the two previous configuraitons. The results are obtained just by calling the fit method of EarlyStoppingTrainer.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510271453933_-750127797","id":"20171108-230018_591188569","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:375","user":"anonymous","dateFinished":"2017-11-09T23:53:39+0000","dateStarted":"2017-11-09T23:53:39+0000"},{"text":"val tempDir : String = System.getProperty(\"java.io.tmpdir\")\nval exampleDirectory : String = FilenameUtils.concat(tempDir, \"DL4JEarlyStoppingExample/\")\nval dirFile : File = new File(exampleDirectory)\ndirFile.mkdir()\n\nval saver  = new LocalFileModelSaver(exampleDirectory)\n\nval esConf  = new EarlyStoppingConfiguration.Builder()\n\t\t.epochTerminationConditions(new MaxEpochsTerminationCondition(10))\n\t\t.iterationTerminationConditions(new MaxTimeIterationTerminationCondition(5, TimeUnit.MINUTES))\n\t\t.scoreCalculator(new DataSetLossCalculator(mnistTest, true))\n        .evaluateEveryNEpochs(1)\n\t\t.modelSaver(saver)\n\t\t.build()\n\nval trainer  = new EarlyStoppingTrainer(esConf,conf,mnistTrain)\nval result = trainer.fit()","dateUpdated":"2017-11-09T23:56:30+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"tempDir: String = /tmp\nexampleDirectory: String = /tmp/DL4JEarlyStoppingExample/\ndirFile: java.io.File = /tmp/DL4JEarlyStoppingExample\nres4: Boolean = false\nsaver: org.deeplearning4j.earlystopping.saver.LocalFileModelSaver = LocalFileModelSaver(dir=/tmp/DL4JEarlyStoppingExample/)\nesConf: org.deeplearning4j.earlystopping.EarlyStoppingConfiguration[org.deeplearning4j.nn.multilayer.MultiLayerNetwork] = EarlyStoppingConfiguration(modelSaver=LocalFileModelSaver(dir=/tmp/DL4JEarlyStoppingExample/), epochTerminationConditions=[MaxEpochsTerminationCondition(10)], iterationTerminationConditions=[MaxTimeIterationTerminationCondition(5,unit=MINUTES)], saveLastModel=false, evaluateEveryNEpochs=1, scoreCalculator=DataSetLossCalculator(org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator@3332e6f7,average=true))\ntrainer: org.deeplearning4j.earlystopping.trainer.EarlyStoppingTrainer = org.deeplearning4j.earlystopping.trainer.EarlyStoppingTrainer@76ceac5f\nresult: org.deeplearning4j.earlystopping.EarlyStoppingResult[org.deeplearning4j.nn.multilayer.MultiLayerNetwork] = EarlyStoppingResult(terminationReason=IterationTerminationCondition,details=MaxTimeIterationTerminationCondition(5,unit=MINUTES),bestModelEpoch=3,bestModelScore=0.1874448861151912,totalEpochs=4)\n"}]},"apps":[],"jobName":"paragraph_1510271453934_-2144739805","id":"20171108-230235_1706388499","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:376","user":"anonymous","dateFinished":"2017-11-10T00:00:22+0000","dateStarted":"2017-11-09T23:55:18+0000"},{"text":"%md\n\nWe can then print out the details of the best model.","dateUpdated":"2017-11-10T00:01:24+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>We can then print out the details of the best model.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510271453934_-919467193","id":"20171108-230434_984201608","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:377","user":"anonymous","dateFinished":"2017-11-10T00:01:24+0000","dateStarted":"2017-11-10T00:01:23+0000"},{"text":"println(\"Termination reason: \" + result.getTerminationReason())\nprintln(\"Termination details: \" + result.getTerminationDetails())\nprintln(\"Total epochs: \" + result.getTotalEpochs())\nprintln(\"Best epoch number: \" + result.getBestModelEpoch())\nprintln(\"Score at best epoch: \" + result.getBestModelScore())","dateUpdated":"2017-11-10T00:02:53+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1510271453937_379132930","id":"20171108-231635_1393261152","dateCreated":"2017-11-09T23:50:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:378","user":"anonymous","dateFinished":"2017-11-10T00:02:55+0000","dateStarted":"2017-11-10T00:02:53+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Termination reason: IterationTerminationCondition\nTermination details: MaxTimeIterationTerminationCondition(5,unit=MINUTES)\nTotal epochs: 4\nBest epoch number: 3\nScore at best epoch: 0.1874448861151912\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1510272086587_-440626530","id":"20171110-000126_889916202","dateCreated":"2017-11-10T00:01:26+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1705"}],"name":"Early Stopping","id":"2CWZ759VN","angularObjects":{"2D19FAWJQ:shared_process":[],"2CYWBRFMG:shared_process":[],"2D12PESPQ:shared_process":[],"2CZ4WMABC:shared_process":[],"2CZTSNRD3:shared_process":[],"2CYWD48D9:shared_process":[],"2CZBZ2UJY:shared_process":[],"2CWR61D5Y:shared_process":[],"2CYC5ZTFJ:shared_process":[],"2CXV4Q3HQ:shared_process":[],"2CXVQ8JQ6:shared_process":[],"2CZTCC5RH:shared_process":[],"2CZCR5PEE:shared_process":[],"2CWNPK6EP:shared_process":[],"2CX1P1U4T:shared_process":[],"2CYVXFSVX:shared_process":[],"2CZ465HM4:shared_process":[],"2CY4YTFTG:shared_process":[],"2CYG4KMRT:shared_process":[],"2CYG4W5Y9:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}